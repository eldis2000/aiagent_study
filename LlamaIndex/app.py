import os
import json
import random
import streamlit as st

from pypdf import PdfReader

from llama_index.core import VectorStoreIndex, Document, Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding


# -----------------------------
# Config
# -----------------------------
APP_TITLE = "ğŸ“˜ PDF ê¸°ë°˜ OX í€´ì¦ˆ ìƒì„±ê¸° (LlamaIndex + Qwen2)"
LLM_MODEL = "qwen2:7b"
EMBED_MODEL = "nomic-embed-text"  # Ollama embedding ëª¨ë¸(ê°€ë³ê³  ë§ì´ ì”€)
CHUNK_SIZE = 1024
CHUNK_OVERLAP = 128


# -----------------------------
# Utils
# -----------------------------
def read_pdf_text(pdf_file) -> str:
    reader = PdfReader(pdf_file)
    texts = []
    for page in reader.pages:
        t = page.extract_text() or ""
        t = t.strip()
        if t:
            texts.append(t)
    return "\n\n".join(texts)


# def build_index_from_text(text: str) -> VectorStoreIndex:
#     # LlamaIndex ê¸€ë¡œë²Œ ì„¤ì •
#     Settings.llm = Ollama(model=LLM_MODEL, request_timeout=120)
#     Settings.embed_model = OllamaEmbedding(model=EMBED_MODEL)
#     Settings.chunk_size = CHUNK_SIZE
#     Settings.chunk_overlap = CHUNK_OVERLAP

#     doc = Document(text=text, metadata={"source": "uploaded_pdf"})
#     index = VectorStoreIndex.from_documents([doc])
#     return index
def build_index_from_text(text: str) -> VectorStoreIndex:
    Settings.llm = Ollama(
        model=LLM_MODEL,
        request_timeout=120,
        base_url="http://localhost:11434"
    )

    Settings.embed_model = OllamaEmbedding(
        model_name=EMBED_MODEL,
        base_url="http://localhost:11434"
    )

    Settings.chunk_size = CHUNK_SIZE
    Settings.chunk_overlap = CHUNK_OVERLAP

    doc = Document(text=text, metadata={"source": "uploaded_pdf"})
    index = VectorStoreIndex.from_documents([doc])
    return index



def generate_ox_questions(query_engine, n_questions: int = 10) -> list[dict]:
    """
    ë°˜í™˜ í˜•ì‹:
    [
      {"q": "...", "answer": "O" or "X", "explain": "...", "evidence": "..."},
      ...
    ]
    """
    prompt = f"""
ë„ˆëŠ” O/X í€´ì¦ˆ ì¶œì œìë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ O/X ë¬¸ì œ {n_questions}ê°œë¥¼ ë§Œë“¤ì–´ë¼.
- ë‹µì€ ë°˜ë“œì‹œ "O" ë˜ëŠ” "X"ë¡œë§Œ.
- ê° ë¬¸í•­ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ.
- ê° ë¬¸í•­ë§ˆë‹¤ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì¥(ë˜ëŠ” í•µì‹¬ êµ¬ì ˆ) 1ê°œë¥¼ evidenceë¡œ í¬í•¨.
- ì„¤ëª…(explain)ì€ 1~2ë¬¸ì¥.

ì•„ë˜ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ë¼. (ì½”ë“œë¸”ë¡ ê¸ˆì§€)
[
  {{"q":"ë¬¸ì œ","answer":"O","explain":"í•´ì„¤","evidence":"ê·¼ê±°ë¬¸ì¥"}},
  ...
]
""".strip()

    # ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•˜ë„ë¡ query_engineì— ì§ˆì˜
    resp = query_engine.query(prompt)
    raw = str(resp).strip()

    # LLMì´ JSON ì•ë’¤ì— í…ìŠ¤íŠ¸ë¥¼ ë¶™ì´ëŠ” ê²½ìš° ëŒ€ë¹„: ê°€ì¥ ë°”ê¹¥ []ë§Œ ì˜ë¼ íŒŒì‹± ì‹œë„
    start = raw.find("[")
    end = raw.rfind("]")
    if start != -1 and end != -1 and end > start:
        raw = raw[start:end + 1]

    try:
        data = json.loads(raw)
        # ê°„ë‹¨ ê²€ì¦
        cleaned = []
        for item in data:
            q = str(item.get("q", "")).strip()
            a = str(item.get("answer", "")).strip().upper()
            explain = str(item.get("explain", "")).strip()
            evidence = str(item.get("evidence", "")).strip()
            if q and a in ("O", "X"):
                cleaned.append({"q": q, "answer": a, "explain": explain, "evidence": evidence})
        return cleaned
    except Exception:
        return []


# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    num_q = st.slider("ë¬¸í•­ ìˆ˜", 5, 30, 10, 1)
    shuffle_q = st.checkbox("ë¬¸í•­ ì„ê¸°", value=True)
    st.caption("LLM: qwen2:7b (Ollama), Embedding: nomic-embed-text")

uploaded = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

if "index" not in st.session_state:
    st.session_state.index = None
if "questions" not in st.session_state:
    st.session_state.questions = []
if "score" not in st.session_state:
    st.session_state.score = 0
if "submitted" not in st.session_state:
    st.session_state.submitted = False


if uploaded:
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("1) PDF ì½ê¸° / ì¸ë±ì‹±")
        if st.button("ğŸ“Œ ì¸ë±ìŠ¤ ìƒì„±", type="primary"):
            with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                text = read_pdf_text(uploaded)

            if not text.strip():
                st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìŠ¤ìº” PDFë©´ OCRì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”)")
            else:
                with st.spinner("LlamaIndex ì¸ë±ìŠ¤ ìƒì„± ì¤‘..."):
                    st.session_state.index = build_index_from_text(text)
                st.success("ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")

    with col2:
        st.subheader("2) OX í€´ì¦ˆ ìƒì„±")
        can_make = st.session_state.index is not None
        if st.button("ğŸ§  í€´ì¦ˆ ìƒì„±", disabled=not can_make):
            with st.spinner("ë¬¸ì„œ ê¸°ë°˜ OX í€´ì¦ˆ ìƒì„± ì¤‘..."):
                qe = st.session_state.index.as_query_engine(similarity_top_k=4)
                qs = generate_ox_questions(qe, n_questions=num_q)

            if not qs:
                st.error("í€´ì¦ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. (ëª¨ë¸ ì¶œë ¥ì´ JSONì´ ì•„ë‹ˆê±°ë‚˜ ê·¼ê±° ë¶€ì¡±)")
            else:
                if shuffle_q:
                    random.shuffle(qs)
                st.session_state.questions = qs
                st.session_state.submitted = False
                st.session_state.score = 0
                st.success(f"í€´ì¦ˆ {len(qs)}ê°œ ìƒì„± ì™„ë£Œ!")

st.divider()

if st.session_state.questions:
    st.subheader("ğŸ“ í€´ì¦ˆ í’€ê¸°")

    answers = []
    for i, item in enumerate(st.session_state.questions, start=1):
        with st.container(border=True):
            st.markdown(f"**Q{i}.** {item['q']}")
            choice = st.radio(
                "ì •ë‹µ ì„ íƒ",
                ["O", "X"],
                horizontal=True,
                key=f"answer_{i}",
                label_visibility="collapsed",
            )
            answers.append(choice)

    colA, colB = st.columns([1, 1])
    with colA:
        if st.button("âœ… ì œì¶œí•˜ê³  ì±„ì ", type="primary"):
            score = 0
            for i, (item, user_a) in enumerate(zip(st.session_state.questions, answers), start=1):
                if user_a == item["answer"]:
                    score += 1
            st.session_state.score = score
            st.session_state.submitted = True

    with colB:
        if st.button("ğŸ”„ ë‹¤ì‹œ í’€ê¸°"):
            st.session_state.submitted = False
            st.session_state.score = 0
            for i in range(1, len(st.session_state.questions) + 1):
                st.session_state[f"answer_{i}"] = "O"

    if st.session_state.submitted:
        st.success(f"ì ìˆ˜: {st.session_state.score} / {len(st.session_state.questions)}")

        st.subheader("ğŸ“Œ í•´ì„¤ & ê·¼ê±°")
        for i, item in enumerate(st.session_state.questions, start=1):
            with st.expander(f"Q{i} í•´ì„¤ ë³´ê¸°"):
                st.markdown(f"- **ì •ë‹µ:** {item['answer']}")
                if item.get("explain"):
                    st.markdown(f"- **í•´ì„¤:** {item['explain']}")
                if item.get("evidence"):
                    st.markdown(f"- **ê·¼ê±°:** {item['evidence']}")
else:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸ë±ìŠ¤ë¥¼ ë§Œë“  ë’¤ í€´ì¦ˆë¥¼ ìƒì„±í•´ë³´ì„¸ìš”.")
