import os
from glob import glob

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

DATA_DIR = "./docs"
INDEX_DIR = "./faiss_index"
EMBED_MODEL = "nomic-embed-text"


def load_documents():
    files = (
        glob(os.path.join(DATA_DIR, "**/*.txt"), recursive=True)
        + glob(os.path.join(DATA_DIR, "**/*.md"), recursive=True)
    )

    if not files:
        raise RuntimeError("âŒ data/ í´ë”ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    docs = []
    for f in files:
        docs.extend(TextLoader(f, encoding="utf-8").load())

    return docs


def build_index():
    print("ğŸ“„ ë¬¸ì„œ ë¡œë”© ì¤‘...")
    docs = load_documents()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=120
    )
    chunks = splitter.split_documents(docs)

    print(f"âœ‚ï¸  ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: {len(chunks)} chunks")

    embeddings = OllamaEmbeddings(model=EMBED_MODEL)

    print("ğŸ§  ì„ë² ë”© ìƒì„± & FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    vectorstore = FAISS.from_documents(chunks, embeddings)

    if os.path.exists(INDEX_DIR):
        print("âš ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ë®ì–´ì“°ê¸°")
    vectorstore.save_local(INDEX_DIR)

    print("âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")


if __name__ == "__main__":
    build_index()
